"""All shared data structures for mini-agent."""

from __future__ import annotations

import time
from enum import Enum
from typing import Any, Literal

from pydantic import BaseModel, Field


# ---------------------------------------------------------------------------
# Content Block types
# ---------------------------------------------------------------------------

class TextBlock(BaseModel):
    type: Literal["text"] = "text"
    text: str


class ImageBlock(BaseModel):
    type: Literal["image"] = "image"
    data: str       # base64 encoded
    mime_type: str  # "image/png", "image/jpeg", etc.


class ToolUseBlock(BaseModel):
    type: Literal["tool_use"] = "tool_use"
    id: str    # tool call ID, generated by LLM
    name: str  # tool name
    input: dict  # raw tool params (unvalidated)


class ToolResultBlock(BaseModel):
    type: Literal["tool_result"] = "tool_result"
    tool_use_id: str
    content: str     # plain text for LLM
    is_error: bool = False


ContentBlock = TextBlock | ImageBlock | ToolUseBlock | ToolResultBlock


# ---------------------------------------------------------------------------
# Message types
# ---------------------------------------------------------------------------

class TokenUsage(BaseModel):
    input_tokens: int = 0
    output_tokens: int = 0
    cache_read_tokens: int = 0
    cache_write_tokens: int = 0

    @property
    def total_tokens(self) -> int:
        return self.input_tokens + self.output_tokens


class UserMessage(BaseModel):
    role: Literal["user"] = "user"
    content: str | list[ContentBlock]
    timestamp: float = Field(default_factory=time.time)


class AssistantMessage(BaseModel):
    role: Literal["assistant"] = "assistant"
    content: list[ContentBlock]
    stop_reason: str | None = None  # "end_turn" | "tool_use" | "max_tokens"
    model: str | None = None
    usage: TokenUsage | None = None
    timestamp: float = Field(default_factory=time.time)


Message = UserMessage | AssistantMessage


# ---------------------------------------------------------------------------
# Tool execution result
# ---------------------------------------------------------------------------

class ToolResult(BaseModel):
    """Tool execution return value. output goes to LLM, details goes to caller/UI."""
    output: str                   # plain text, sent to LLM as tool_result content
    details: dict[str, Any] = {}  # structured data, NOT sent to LLM
    is_error: bool = False


# ---------------------------------------------------------------------------
# Agent events
# ---------------------------------------------------------------------------

class EventType(str, Enum):
    AGENT_START = "agent_start"
    AGENT_END = "agent_end"
    TURN_START = "turn_start"
    TURN_END = "turn_end"
    TEXT_DELTA = "text_delta"           # streaming text fragment from LLM
    TOOL_CALL_START = "tool_call_start"
    TOOL_CALL_END = "tool_call_end"
    TOOL_RESULT = "tool_result"
    ERROR = "error"
    COMPACTION = "compaction"           # fired when context is compacted


class AgentEvent(BaseModel):
    type: EventType
    data: dict[str, Any] = {}
    timestamp: float = Field(default_factory=time.time)


# ---------------------------------------------------------------------------
# Agent state
# ---------------------------------------------------------------------------

class AgentState(BaseModel):
    system_prompt: str
    model: str                      # model ID, e.g. "claude-sonnet-4-20250514"
    messages: list[dict] = []       # Anthropic SDK format message list
    tools: list[str] = []           # registered tool names
    total_usage: TokenUsage = Field(default_factory=TokenUsage)


# ---------------------------------------------------------------------------
# Provider config
# ---------------------------------------------------------------------------

class ProviderConfig(BaseModel):
    """Anthropic provider config. Supports pointing to an internal endpoint."""
    api_key: str | None = None          # None → read from ANTHROPIC_API_KEY env
    base_url: str | None = None         # None → official endpoint; set to point internally
    model: str = "claude-sonnet-4-20250514"
    max_tokens: int = 8096
    timeout: float = 300.0              # request timeout in seconds
    default_headers: dict[str, str] = {}  # extra headers for internal endpoints
